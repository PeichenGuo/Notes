---
Book: 超标量流水线设计
Author: 姚永斌
Summary: BlaBla
---
# Intro
#skip 
# Cache
部分参见CAQA的[[Cache]]
## 一般设计
### 组成方式
#skip 
### 写入
write allocate / write non-allocate
write back / write through
#skip
### 替换策略
#### LRU和MRU
LRU的硬件实现开销太大，一般是pLRU。一般使用的实现方式是treeLRU
https://www.cnblogs.com/wangzheming35/p/15646046.html
![[Pasted image 20240827150453.png]]
与之类似的事MRU，替换的事最新的。在项目越旧访问可能性越大的程序中有用。
#### LFU Least-Frequently Used
记录每个被访问的次数，访问次数最少的被淘汰。
该替换算法对 那些符合不相关访问模型的工作负载具有比较好的 表现，比如随机 B-tree的查找
#### LRFU：LFU+LRU
LRFU算法的基本思想是采用一个权值函数， 该函数对所有以前的访问进行评估，其评估原则要 兼顾recency(最近访问时间)和 frequency(频繁访 问时间)两个特性，并且最近一次访问所占权值最 大，越往后其权值越小。该权值被称作CRF(Combined Recency and Frequency)值，表示该块未来被 访问的可能，是进行块替换的依据
#### LRU-K
https://www.yanceymichael.com/2019/07/13/%E6%B7%98%E6%B1%B0%E7%BC%93%E5%AD%98%E7%AE%97%E6%B3%95LRU/
LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。
具体实现方式是：
- 有个历史列表存放最近的访问，每次访问都进入这个列表
- 如果数据在访问历史列表中没有被访问到k次，则按照一定规则淘汰（FIFO，LRU）
- 当访问达到k次时，将访问数据从历史队列里删除，进行LRU更新
#### 2Q 2-Queues
给L2设计的。称之为本地缓存 算法，因为它无需从一级缓存中得到任何信息.
2Q类似LRU-2，其历史记录队列是FIFO的，还有一个LRU队列。
一个信息先进FIFO，如果在FIFO周期内都没有第二次访问，则被弹出；如果被访问，则弹出进去LRU队列（更新pLRU树）
#### MQ
MQ就是很多个优先级不同的queue。可以是很多个LRU queue。
数据进来后先进入Q0,多次访问后进入Q1，即提升优先级。
一定时间内没有被访问的数据，会降低优先级。
需要淘汰数据则从最低一级的LRU队列开始淘汰
## 提高cache性能的方式
具体参见CAQA的[[Cache]]
### victim cache
一个较小(4-16)的全相连cache，保存最近被踢出的cacheline。
本质是增加了way的个数，相当于一个灵活的额外way存储区。
访问时同时查找victim和cache，如果victim hit了，就把victim的cacheline写入cache之中。
### filter cache
有个类似victim cache的设计叫filter cache，只不过放在cache之前。类似cache的cache。一个数据第一次被使用时放入filter cache，只有在第二次被使用的时候才会写入cache。如果一个数据没有被访问则被抛弃。

### Prefetch
对于icache而言，prefetch不仅可以提前取值，还可以防止branch指令污染cache。Icache缺失的时候，会顺便读出下一个block放在stream buffer里。如果i cache确实，且在stream buffer里找到想要的指令，那么就把stream buffer的内容放进cache。
![[Pasted image 20240827160123.png]]
branch后就将stream buffer清空。
预取可能减少缺失率，但也可能浪费功耗和带宽。

## 多端口cache
 - True multi-port。主要是面积大，而且多口下latency也长。
 - duplicate。浪费面积，不常见
 - multibanking。有可能conflict。所以有可能read write replay。




# 虚拟存储器

# 分支预测
可参考[[Advanced Instruction Flow Techniques]]和[[ILP]]这两章
## 分支指令的方向预测
### 两位饱和计数器
早期现代处理器的分支预测基本上是基于两位饱和计数器（2-bit saturating counter）的分支预测

4个状态：
- Strongly taken: 11
- Weakly taken: 10
- Weakly not taken: 01
- Strongly not take: 00
每次taken counter++，每次not taken counter--。
在不同的benchmark上不同的初始状态效果不一样。
极限值大概是98%左右，因此现代处理器不太常用这个了

PHT (predict history table)
存储各种饱和计数器。
由于不可能每个pc都对应一个饱和计数器，所以一定存在某种映射来缩小预测空间。
不同pc映射到同一个计数器的情况叫做重名。
比较常见的避免重名的方式有就是hash
### 基于历史记录的分支预测
BHR （Branch History Register）
记录过去n次预测结果（图4.14）
![[Pasted image 20240827173015.png]]
可以用BHR去访问PHT获得counter的结果，n位BHR需要2^n个PHT
多个BHR组成一个表叫做BHT或者BHRT
不可能每个pc都有一个BHR，需要构成一个映射，pc中的一段会映射到同一个BHR
同时也可以用pc另一段来让同一个BHR映射到不同的PHT entry。
为了避免重名问题，还是可以使用hash来解决。

得到BHR和PC后，可以位拼接法来寻址PHT（就是简单的二维数组访问），但这样做效果不好。也可以使用异或法，讲BHR和PC异或后寻址
![[Pasted image 20240827173358.png]]
### 基于全局历史的分支预测
GHR(Global History Register)

用一个全局的分支跳转记录和pc来寻址一个PHT entry。同样的，可以对pc进行hash来避免冲突。其余操作和本地历史记录的分支预测没有什么差异

### 竞争的分支预测
GHR和BHR一起用
CPHT(Choice PHT)，相当于一个记录PHT选择的PHT，大小和两个预测的PHT相同。像拔河一样，如果一方赢了就向一方偏移，如果都没有命中或者都命中了，则保持不动
![[Pasted image 20240827173728.png]]
### 分支预测的更新
分支预测更新：
有两个东西要更新：BHR/GHR和PHT

对于GHR来说，有三个时机可以更新：
- commit时更新：有可能会延迟更新，导致最近的branch没有被考虑在内，对于基于历史的判断来说，是非常伤的
- exe结束时根据branch算出的结果进行更新：比commit时更新快很多，但还是有延迟
- fetch阶段根据预测结果更新：最快的。并且预测错误后导致的连续预测错误是无所谓的，反正后面的预测都会被杀掉。但需要rollback机制

两种rollback机制：
- 在commit阶段维护一个正确的GHR，错误的时候更新到fetch的GHR里。缺点是会造成分支预测失败的开销变大（因为要一直等到commit的时候才能维护正确的GHR，时间慢了很多）
- checkpoint：保存旧的GHR，当exe阶段预测错误的时候回复旧的GHR。类似一个fifo。但因为exe阶段的结果可能是暂时的（exception或者在错误预测执行下），因此还是需要一个commit reg来做一个正确替代。即这个方式下，正常情况的预测修复可以提前，而特殊情况比如exception或者本身就是错误预测执行下的预测错误，还是要靠commit阶段修复。

BHR和GHR类似，但不太可能连续多次出现同一个BHR的连续访问（连续的pc会被映射到不同的BHR）。因此只在commit时更新就可以

## branch目标地址预测
### 直接跳转的分支预测
BTB Branch Target Buffer:
就是一个cache，pc到offset的映射
但pc其实挺长的，有点浪费空间。可以采用partial tag的方法。在普通的直接映射里，在partial tag出现重名的情况时，一定会出现缺失。都是预测失败，其实没啥区别。

BTB缺失时的两个做法：
- 暂停流水线，然后等decode阶段算出offset然后拿回来用
- 继续流水线，BTB缺失后用继续执行的流水线来fetch，发现不对后flush掉
### 间接跳转的分支预测：
#### call/return 预测
RAS Return Adress Stack
每次call把pc+4压栈。return的时候pop栈顶的address
用BTB预测call，用RAS预测return
RAS可能的错误：
- 当call指令进入decode压栈前，已经有return进入流水线，此时return的地址还来不及压栈。可以用BTB来预判其是否为跳转指令，从而提前压入PC+4，这时就可以避免这种错误。
- 在fetch的时候就需要知道其return的类型，也可以通过btb来解决。
在call的嵌套次数超过RAS深度的时候，两种做法：
- 丢弃最新的call，不修改RAS:一定会发生错误，因为没有进行分支预测，在间接跳转的情况下基本上是错的
- 丢弃最老的call：有可能对，比如自身连续嵌套的时候，有可能预测对
## 分支指令的恢复
在不同的阶段需要进行不同的处理：

1. 解码阶段： 解码阶段可以判断是否为跳转，判断是什么类型的跳转。直接跳转可能可以直接得到目的地址。此时可以预测到直接跳转的成功与否，如果失败了可以暂停流水线，等待j指令获得目标地址。
2. depatch阶段：此时会读寄存器。可以得知间接跳转预测的地址是否正确，如果预测地址是错的，那么本次预测不可能成功。因此可以使用正确地址重新取指令，杀掉之前的指令。这部分挺难的。
3. exe阶段，可以确定一个指令的预测是否正确。

恢复方式：

- 先写到ROB里，mark这条指令是错误的，当这条branch成为最老的指令时，flush rob以及后面所有，同时取指
- 基于checkpoint的回复方式：保存映射表 保存pc 需要在decode阶段给分支指令分配一个tag。清空发射前的所有指令，清空发射后的错误分支指令tag后面的所有tag。（因为发射前指令保序，因此一定处于错误预测路径内）。

检查跳转是否正确的做法：
PTAB Predict Target Address Buffer
只存那些预测方向是跳转的指令。如果指令不在PTAB里，那么说明当时的预测是不跳转，也就是PC+4

## 超标量流水线的分支预测
一般是一个fetch group作为一个预测对象，即PHT和BTB里放的东西是pc的一部分

对fetch group里每条pc都进行预测不是不行，硬件开销太大，而大多数情况下一个fetch group里只有一个branch指令

RISC程序中有很多直接跳转，可以直接通过提前解码得到，相当于从icache里拿出来后直接算目的地址

需要每周期对多条指令是否为branch进行判断，因此PHT和BTB都要支持同时访问

# 指令集体系
#skip

# Decode
#skip 

# 寄存器重命名
## 实现方式
目的：解决WAW和WAR的相关性
本质：架构寄存器->物理寄存器的实现方式
三种实现方式：
- 架构寄存器(APF)扩展
- 物理寄存器堆PRF重分配
- ROB分配
### ROB分配
APF存正确结果，ROB存暂时的结果。在commit的时候ROB将正确的值存入APF
用一个mapping table来指示最新的值是在ROB里还是APF里。（比如rob里有一个add写入rd，此时最新的是rob的值，不是apf的值）
缺点：
- 不是所有指令都会要目的寄存器，造成浪费
- ROB和APF都要支持全读，比如4发射就要支持4读，开销很大
### APF扩展
类似ROB，有个表在旁边存储正确数据，每次commit的时候写入PRF。也需要一个mapping table

### 统一的PRF
一个free list来存储所有retire的reg。每次用的时候从free list里分配一个
需要维护一个renaming table来记录架构寄存器到物理寄存器的映射，这个Renaming table 在Intel被称为RAT

## Renaming Table
两种实现方式：
- SRAM：存的是APF->PRF的映射，checkpoint需要保存所有表项
- CAM：存的是PRF->APF的映射，checkpoint存的是valid内容
CAM只需要保存valid状态就能做checkpoint，因为只有在commit的时候寄存器才会被retire，不会有需要保存的映射被覆盖的情况

当指令开始重命名的时候，进行checkpoint

重命名的三步：
- 读renaming table获得prs1和prs2
- 从freelist里拿个寄存器给rd
- 将rd->prd的映射写入renaming table

## 重命名的恢复
基于checkpoint：需要用的特别的硬件SAGC或者RAGC，开销大。
WALK:因为ROB里有物理寄存器的地址，实际可以用rob的内容逐行恢复RAT，比较慢
aRAT：在commit时维护一个RAT，只有正确离开的指令才会更新在这个rat里。此时这个RAT其实就是某条prd刚被分配的时候的RAT。在需要恢复的时候直接把aRAT覆盖RAT就可以了

# Issue
## 概述
四个比较重要的组成部分：

- 发射队列
- 分配电路：在发射队列里找空间
- 选择电路：选择准备好的指令发出去
- Wake-up电路 ：唤醒发射队列里的指令
发射队列的几种设计：
### 分布式vs集中式:
 集中式CIQ(Centralized Issue Queue):利用率高 不浪费发射队列里的每一个空间，但是选择电路和唤醒电路的复杂度上升
 
分布式DIQ (Distributed Issue Queue):每个fu配一个。简化电路设计，但是利用率低，且突发的时候容易阻塞。（比如一段时间内只有加减法指令）

 现代处理器一般是结合CIQ和DIQ，将多个fu放在一起做一个queue
### 数据捕捉vs非数据捕捉：
 数据捕捉(Data-Captured) 在发射前读寄存器。如果src寄存器还没准备好，先写一个src index。每个指令结束运行的时候会广播自己的rd，如果rd是自己的rs，则可以通过bypass来写入issue que。好处是寄存器堆的口数一般比较少。缺点一是需要存操作数，IQ面积大；二是操作数需要从prf里读出来，写入IQ，再立刻读出来发给fu，多了一读一写，功耗大。
 
 非数据捕捉：在issue后读寄存器。当被选择issue的时候才去访问寄存器堆，直接把数据发给fu。与数据捕捉方法相反，读口多但IQ面积小、功耗小。
### 压缩vs非压缩：
压缩：将队列中issue过的从IQ中拍出，后面的entry前移。好处很明显，选择电路和分配电路容易，因为队列时刻保持新旧顺序。坏处也明显，复杂的逻辑会增大电路面积，每次前移会增加能耗。
非压缩：和压缩相反，谁issue了谁出列，list中指令顺序是混沌的。因此需要实现oldest-first的算法，有较大面积开销。分配电路也不好写。好处是减少了每周期移动的电路开销。
## 发射过程中的流水线

### 非数据捕获
如果有两条指令是RAW关系，可以等一个指令彻底结束后再wakeup吓一跳指令。此时就是tomosulu算法
![[Pasted image 20240827194204.png]]
如果想要RAW背靠背执行，则需要将仲裁和选择放在一个周期进行。
但放在一个周期内时序会变长。
![[Pasted image 20240827202335.png]]
而如果分两个周期的话，bypass比较复杂，IPC会下降。这也是也跟trade-off问题


数据捕获：
因为读数据时间比较长，需要单独的一个周期

# 执行

# Commit

# Alpha21264
