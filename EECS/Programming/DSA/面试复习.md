基于OI wiki
# 算法基础
## 贪心
在提高组难度以下的题目中，最常见的贪心有两种。

- 「我们将 XXX 按照某某顺序排序，然后按某种顺序（例如从小到大）选择。」。
- 「我们每次都取 XXX 中最大/小的东西，并更新 XXX。」（有时「XXX 中最大/小的东西」可以优化，比如用优先队列维护）

## 排序
### 选择排序
每次找到第i小的元素，然后和第i位元素交换。非常简单的想法。
最优复杂度 平均复杂度 和 最坏复杂度都是O(n2)

### 冒泡排序
每次对比相邻元素，如果左边的元素大，就和右边的交换
第一次扫i个，第二次扫i-1个

在完全有序的情况下，只需要遍历一遍数组，不交换，时间复杂度O(n)
最坏情况是全部要交换，O(n2)

### 插入排序
分为已分类和未分类两个部分，每次都选择一张牌进入已分类的部分，把他插入到其对应位置。
类似打扑克时抓牌理牌的过程
插入排序的最优时间复杂度为 O(n)，在数列几乎有序时效率很高。
插入排序的最坏时间复杂度和平均时间复杂度都为O(n2)
![[Pasted image 20240826160411.png]]

### 计数排序
使用额外的一个数组，其第i个元素是待排序数组中数值为i的元素的个数，然后再用前缀和的方式计算排位
复杂度是O(n+w) 其中w是待排序数的值域


### 基数排序
基数排序（英语：Radix sort）是一种非比较型的排序算法，最早用于解决卡片排序的问题。基数排序将待排序的元素拆分为k个关键字，逐一对各个关键字排序后完成对所有元素的排序。比如字符串排序。
分为MSD和LSD。 Most/Least Significant Digit first.


### 快速排序
快速排序分为三个过程：

1. 将数列划分为两部分（要求保证相对大小关系）；
2. 递归到两个子序列中分别进行快速排序；
3. 不用合并，因为此时数列已经完全有序。

最优和平均时间复杂度是nlogn 最坏情况是n2
最优情况下，分界值都是中位数，因此形成二叉树，是一个nlogn
最坏情况每次pivot都是最值，变成插入排序

在实践中，几乎不可能达到最坏情况，而快速排序的内存访问遵循局部性原理，所以多数情况下快速排序的表现大幅优于堆排序等其他nlogn的排序算法。

我们需要对朴素快速排序思想加以优化。较为常见的优化思路有以下三种

- 通过 **三数取中（即选取第一个、最后一个以及中间的元素中的中位数）** 的方法来选择两个子序列的分界元素（即比较基准）。这样可以避免极端数据（如升序序列或降序序列）带来的退化；
- 当序列较短时，使用 **插入排序** 的效率更高；
- 每趟排序后，**将与分界元素相等的元素聚集在分界元素周围**，这样可以避免极端数据（如序列中大部分元素都相等）带来的退化。

三路快排

## 数据结构
### ST表
区间最值问题的解决办法。
对于每位i，都维护一个ST表，其表项f(i,j)的意思是,\[i, i + 2^j - 1\]的最值
如此:
![[Pasted image 20240826201940.png]]
然后用nlogn的办法建表
![[Pasted image 20240826202126.png]]
对于每个询问，都能找到两段：从左起点开始向右的一个2的整数幂，从右起点开始的一个2的整数幂。这两段相交，所以两段的最值的最值一定是整段的最值
![[Pasted image 20240826202242.png]]
### 线段树
可以用来求区间性质，比如区间和
![[Pasted image 20240826202548.png]]
可以用懒惰标记维护，即修改时只在上层修改，用到的时候向下传播修改。

### 二叉搜索树
#### AVL
一种二叉平衡搜索树，意思就是一个节点的左右子树高度相差不超过1
平衡的办法：进行旋转。如下图，假设h(b) - h(e) = 2，不满足条件，需要重新平衡，有两种可能。
![[Pasted image 20240826203156.png]]
如果此时h(A) >=  h(C)，d进行右旋
![[Pasted image 20240826203045.png]]
如果h(c) > h(a)，b进行左旋，d再进行右旋
![[Pasted image 20240826203518.png]]

#### B树
在计算机科学中，B 树（B-tree）是一种自平衡的搜索树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B 树的每个节点可以拥有两个以上的子节点，因此 B 树是一种多路搜索树。

在 B 树中，有两种节点：

1. 内部节点（internal node）：存储了数据以及指向其子节点的指针。
2. 叶子节点（leaf node）：与内部节点不同的是，叶子节点只存储数据，并没有子节点
![[Pasted image 20240826203755.png]]
每个节点还有一个阶数，就是这个节点能承载的最多元素个数。在插入时如果超过个数，就需要分裂该节点。分裂的方式就是选一个中位数，比这个数小的进入左节点，比这个数大的进入有节点，中位数作为分割值进入父节点。父节点也有可能裂开。

![[Pasted image 20240826204416.png]]
删除比较麻烦，有很多种情况。
首先是删除后本节点个数大于最小个数，就删掉就好，不用管；
如果本节点个数小于最小个数，就要借一个数。如果有子节点，可以借子节点一个；如果子节点没有，一般是向父节点借一个，然后父节点向该节点的相邻节点借一个，相当于转一圈
![[Pasted image 20240826204917.png]]
删除23后
![[Pasted image 20240826204923.png]]
如果相邻节点不够借，则直接向父节点借一个，然后组成一个新节点
![[Pasted image 20240826205403.png]]
此时又出现相邻节点不够借的情况，直接合并节点。
![[Pasted image 20240826205503.png]]
#### B+树
文件系统是b+树实现的
![[Pasted image 20240826205617.png]]
即非叶子节点不存值，只是子节点数据的复制，用来标记子节点；只有叶子节点存数据，指向数据的指针
![[Pasted image 20240826205812.png]]
#### 红黑树
![[Pasted image 20240826205949.png]]
![[Pasted image 20240826210019.png]]
维护红黑树的性质是重点。
插入的节点是红色，完成插入后要重新平衡树。有三种违例可能。
1. 父节点和叔节点是红色，直接递归染色：![[Pasted image 20240826211200.png]]
2. 父节点是红色，叔节点是黑色，且插入的节点是父节点的相反节点。即父节点是爷节点的左节点，但插入节点是右节点；父节点是爷节点的有节点，但插入节点是左节点。此时左旋或者右旋，调整到情况3，也就是相同节点。![[Pasted image 20240826211351.png]]
3. 父节点是红色，叔节点是黑色，且插入的节点是父节点的同向节点。此时如果简单地交换N和G的颜色，则第四条标准被打破，即根节点到任何叶节点时路过的黑色节点数量不同了（即高度差距大于1）。所以不能简单交换颜色，需要转。如果此时N节点为左节点，则右旋组父节点；否则左旋组父节点。旋转过程相当于平衡高度。然后重新染色。    ![[Pasted image 20240826211700.png]]

删除时有两种情况会打破平衡。第一种是删除的节点既有左节点又有右节点，需要提一个节点上来；第二种是删除的叶节点为黑色

### kd 树
![[Pasted image 20240826213515.png]]
建树是nlogn
## 搜索
### 双向搜索
从起点和终点同时开搜，如果两端相遇，就认为获得了可行解。
可以让搜索在指数上折半

### A*
https://www.cnblogs.com/ISGuXing/p/9800490.html
　　利用当前与问题有关的信息作为启发式信息，这些信息是能够提升查找效率以及减少查找次数的。

如何使用这些信息，我们定义了一个估价函数 h(x) 。h(x)是对当前状态x的一个估计，表示 x状态到目标状态的距离。

有：**1、h(x) >= 0 ；  2、h(x)越小表示 x 越接近目标状态； 3、如果 h(x) =0 ，说明达到目标状态。**

与问题相关的启发式信息都被计算为一定的 h(x) 的值，引入到搜索过程中。

　　然而，有了启发式信息还不行，还需要起始状态到 x 状态所花的代价，我们称为 g(x) 。比如在走迷宫问题、八数码问题，我们的 g(x) 就是从起点到 x 位置花的步数 ，h(x) 就是与目标状态的曼哈顿距离或者相差的数目；在最短路径中，我们的 g(x) 就是到 x 点的权值，h(x)  就是 x 点到目标结点的最短路或直线距离。

　　现在，从 h(x) 和 g(x) 的定义中不能看出，假如我们搜索依据为 F(x) 函数。

　　当 **F(x) = g(x)** 的时候就是一个等代价搜索，完全是按照花了多少代价去搜索。比如 bfs，我们每次都是从离得近的层开始搜索，一层一层搜 ；以及dijkstra算法，也是依据每条边的代价开始选择搜索方向。 

　　当**F(x) = h(x)** 的时候就相当于一个贪婪优先搜索。每次都是向最靠近目标的状态靠近。

　　人们发现，等代价搜索虽然具有完备性，能找到最优解，但是效率太低。贪婪优先搜索不具有完备性，不一定能找到解，最坏的情况下类似于dfs。

　　这时候，有人提出了A算法。令**F(x) = g(x) + h(x)** 。（**这里的 h(x) 没有限制**）。虽然提高了算法效率，但是**不能保证找到最优解**，不适合的 h(x)定义会导致**算法找不到解。不具有完备性和最优性**。

　　几年后有人提出了 A*算法。该算法仅仅对A算法进行了小小的修改。并证明了当估价函数满足一定条件，算法**一定能找到最优解**。估价函数满足一定条件的算法称为A*算法。

它的限制条件是 F(x) = g(x) + h(x) 。 **代价函数g(x) >0 ；h(x) 的值不大于x到目标的实际代价 h*(x) 。即定义的 h(x) 是可纳的，是乐观的**。  

怎么理解第二个条件呢？

　　打个比方：你要从x走到目的地，那么 h(x) 就是你感觉或者目测大概要走的距离，h*(x) 则是你到达目的地后，发现你实际走了的距离。你预想的距离一定是比实际距离短，或者刚好等于实际距离的值。这样我们称你的 h(x) **是可纳的，是乐观的。**

　不同的估价函数对**算法的效率**可能产生极大的影响。尤其是 h(x) 的选定，比如在接下来的八数码问题中，我们选择了**曼哈顿距离之和作为 h(x)** ，你也可以选择**相差的格子**作为 h(x)，只不过搜索的次数会不同。**当 h(x) 越接近 h*(x) ，那么扩展的结点越少！**

### Alpha-Beta剪枝
https://oi-wiki.org//search/alpha-beta/
是min max的优化版本。min max就是树搜索，一层是min 一层是max。但这样的话树节点太多，需要剪枝。
==alpha是一个节点分数的最大下界，beta是最小上界。==
max节点的子节点，其中如果有比alpha更大的值或者beta，则更新最大下界alpha；min节点如果有比beta更小的值或alpha，则更新最小下界beta。
父节点会向下更新子节点的alpha beta值
当alpha大于beta，则不用继续搜索了（剪枝）